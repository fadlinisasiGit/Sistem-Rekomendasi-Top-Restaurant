# -*- coding: utf-8 -*-
"""SistemRekomendasi_Submission(revisi).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DSmqz8ItPFXVLc15XwAMMSd_hEoOJ1S_

# Project Overview

## Merekomendasikan restoran teratas berdasarkan preferensi konsumen menggunakan popularitas dan sistem rekomendasi kolaboratif

# Business Understanding

Mengistal paket kaggle
"""

# Install packages kaggle
!pip install -q kaggle
from google.colab import files
files.upload()

"""Membuat direktori kaggle"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""# Data Understanding

Import paket dan download dataset
"""

# Commented out IPython magic to ensure Python compatibility.
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = 'all' 

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import scipy.sparse

import warnings
warnings.simplefilter('ignore')

"""Mendownload dataset menggunakan API Command Kaggle"""

!kaggle datasets download -d uciml/restaurant-data-with-consumer-ratings --force

"""Membuka zip file dataset"""

# Membuka zip pada dataset
!unzip /content/restaurant-data-with-consumer-ratings.zip

"""Terdapat 10 file yang terdapat pada folder dataset tersebut. Namun, kita hanya menggunakan dataset yang berasal dari file rating_final.csv


"""

# Membaca data - data diatas menggunakan fungsi pandas.read_csv
data = pd.read_csv('rating_final.csv')
data

"""Menampilkan informasi tipe data pada kolom"""

data.info()

"""Ringkasan statistik dataset"""

data.describe(include = 'all').transpose()

"""## Exploratory Data Analysis

Tahap eksplorasi penting untuk memahami variabel-variabel pada data serta korelasi antar variabel. Pemahaman terhadap variabel pada data dan korelasinya akan membantu kita dalam menentukan pendekatan atau algoritma yang cocok untuk data kita.

## Exploratory Data Analysis

Untuk memahami dataset secara detail, penting untuk melakukan EDA.

**Mari kita jawab beberapa pertanyaan:**
* Jumlah pengguna unik, restoran unik, no. rating, food_ratings, service_ratings
* Berapa kali pengguna menilai
* Berapa kali restoran dinilai
* Bagaimana distribusi peringkat untuk makanan, layanan?

Untuk menjawab pertanyaan tersebut, kita perlu mengeksplorasi data yang kita dapatkan sesuai dengan pertanyaan diatas.
"""

#Jumlah user unik, restaurant unik, rating, rating makanan, dan rating layanan yang diberikan
print('users unik: ', data['userID'].nunique())
print('restaurant unik: ', data['placeID'].nunique())
print('Total banyaknya rating yang diberikan: ', data['rating'].count())
print('Total banyaknya rating makanan yang diberikan: ', data['food_rating'].count())
print('Total banyaknya rating layanan yang diberikan: ', data['service_rating'].count())

# Berapa kali user dinilai 
most_rated_users = data['userID'].value_counts()
most_rated_users

# Berapa kali restoran dinilai
most_rated_restaurants = data['placeID'].value_counts()
most_rated_restaurants

"""Menampilkan visualisasi data distribusi rating, rating makanan dan rating layanan"""

# Visualisasi data distribusi rating
plt.figure(figsize = (8,5))
sns.countplot(data['rating'])

# Visualisasi data distribusi rating makanan
plt.figure(figsize = (8,5))
sns.countplot(data['food_rating'])

# Visualisasi data distribusi rating layanan
plt.figure(figsize = (8,5))
sns.countplot(data['service_rating'])

"""**Dengan EDA ini, kita dapat menyimpulkan:**

- Semua 130 restoran dinilai minimal 3 kali dalam skala 0 hingga 2
- Semua 138 pengguna telah memberi peringkat minimal 3 kali
- Untuk distribusi rating, pengguna cukup puas dengan restoran karena tidak signifikan. pengguna telah memberi peringkat 1,2

Jumlah no. dari peringkat adalah 1161, namun jika masing-masing pengguna akan menilai semua restoran itu akan menjadi total 138 * 130 = 17940 peringkat

Untuk model sistem rekomendasi untuk merekomendasikan restoran pilihan teratas, kita harus meminta setiap pengguna memberi peringkat semua restoran. Karena ini tidak mungkin, kami harus memprediksi peringkat yang akan diberikan pengguna ke restoran.

Mari kita buat kumpulan data yang berisi pengguna yang telah secara aktif memberi peringkat setidaknya n kali.
"""

# Berapa banyak user yang memberi rating lebih dari n
n = 3
user_counts = most_rated_users[most_rated_users > n]
len(user_counts)
user_counts

# Banyak rating yang diberikan
user_counts.sum()

# Semua data rating yang diberikan user
data_final = data[data['userID'].isin(user_counts.index)]
data_final

"""# Data Preparation"""

# Mengubah data menjadi matriks
final_ratings_matrix = data_final.pivot(index = 'userID', columns = 'placeID', values='rating').fillna(0)
final_ratings_matrix.head()

# Kalkulasikan densitas matriks. Ini untuk melihat berapa banyak kemungkinan peringkat yang bisa diberikan dan berapa tepatnya peringkat yang diberikan

# Banyak rating yang diberikan
given_num_of_ratings = np.count_nonzero(final_ratings_matrix)
print('banyak rating yang diberikan: ', given_num_of_ratings )

# Total banyaknya peniilaian yang bisa diberikan
possible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]
print('Banyak kemungkinan rating: ', possible_num_of_ratings)

# Menghitung densitas matriks
density = (given_num_of_ratings / possible_num_of_ratings) * 100
print('density: {:4.2f}%'.format(density))

"""## Mengatasi Missing Values

Memeriksa missing values pada variabel data_final
"""

# Memeriksa missing value dengan fungsi isnull()
data_final.isnull().sum()

"""Dikarenakan dalam variabel data_final tidak memiliki msissing value, menandakan bahwa data telah bersih dan siap di gunakan untuk modeling

# Modeling and Result

Untuk modeling kita menggunakan dua solusi rekomendasi dengan algoritma yang berbeda, yaitu :
- Popularity based Recommender Model
- Collaborative Filtering Model

Banyak peringkat adalah 0 jadi kami tidak yakin apakah mereka benar-benar 0 atau pengguna belum memberi peringkat.

# Popularity based Recommender Model

Seperti namanya, ini merekomendasikan berdasarkan apa yang sedang tren/populer di seluruh situs. Ini sangat berguna ketika Anda tidak memiliki data masa lalu sebagai referensi untuk merekomendasikan produk kepada pengguna. Ini tidak cocok untuk kelompok penonton atau film tertentu.

*Untuk pemahaman yang lebih baik, Anda dapat merujuk ke kernel -> [Rekomendasi Film Berbasis Popularitas](https://www.kaggle.com/sasha18/popularity-based-movie-recommendation)*

**Hal yang harus dilakukan:**
* Jumlah pengguna yang telah memberi peringkat resto
* Beri peringkat berdasarkan skor
* Rekomendasikan tempat paling populer
"""

# Jumlah user tang rating 
data_grouped = data.groupby('placeID').agg({'userID':'count'}).reset_index()
data_grouped.rename(columns = {'userID': 'score'}, inplace = True )
data_sort = data_grouped.sort_values(['score','placeID'], ascending = False)
data_sort.head()

# Perigkatkan berdasarkan nilai scores
data_sort['Rank'] = data_sort['score'].rank(ascending = 0, method = 'first')
pop_recom = data_sort
pop_recom.head()

print('Ini adalah Restoran terpopuler')
pop_recom[['placeID','score','Rank']].head()

"""Karena ini adalah rekomendasi berdasarkan popularitas, ini tidak dipersonalisasi sehingga rekomendasi tetap sama untuk semua pengguna.

## Collaborative filtering model

Menggunakan model based collaborative filtering :SVD (Singular Value Decomposition)

**Hal yang harus dilakukan:**
* Ubah data menjadi tabel pivot -> Format diperlukan untuk model colab
* Buat kolom user_index untuk menghitung no. pengguna -> Ubah konvensi penamaan pengguna dengan menggunakan penghitung
* Terapkan metode SVD pada matriks sparse besar -> Untuk memprediksi peringkat untuk semua resto yang tidak diberi peringkat oleh pengguna
* Prediksi peringkat untuk semua restoran yang tidak dinilai oleh pengguna menggunakan SVD
* Bungkus semuanya menjadi sebuah fungsi
"""

# Mengubah data menjadi pivot table, format ini dibutuhkan untuk model colab
pivot_data = data_final.pivot(index = 'userID', columns = 'placeID', values = 'rating').fillna(0)
pivot_data.shape
pivot_data.head()

# Buat kolom user_index untuk menghitung no. pengguna -> Ubah konvensi penamaan pengguna dengan menggunakan penghitung
pivot_data['user_index'] = np.arange(0, pivot_data.shape[0],1)
pivot_data.head()

pivot_data.set_index(['user_index'], inplace = True)
pivot_data.head()

# Terapkan metode SVD pada matriks sparse besar -> Untuk memprediksi peringkat untuk semua resto yang tidak diberi peringkat oleh pengguna
from scipy.sparse.linalg import svds

# SVD
U,s, VT = svds(pivot_data, k = 10)

# Kontruksi diagonal array di SVD
sigma = np.diag(s)

# Menerapkan SVD akan menamai 3 parameter output
print("U = ",U) # Matriks Ortogonal
print('---------------------------------------------------------')
print("S = ",s) # Nilai tunggal
print('---------------------------------------------------------')
print("VT = ", VT) #Transpose matriks ortogonal

"""Perhatikan bahwa untuk matriks sparse, Anda dapat menggunakan fungsi sparse.linalg.svds() untuk melakukan dekomposisi. SVD berguna dalam banyak tugas, seperti kompresi data, pengurangan kebisingan mirip dengan Analisis Komponen Utama dan Pengindeksan Semantik Laten (LSI), digunakan dalam pengambilan dokumen dan kesamaan kata dalam penambangan teks"""

# Prediksi peringkat untuk semua restoran yang tidak dinilai oleh pengguna menggunakan SVD
all_user_predicted_ratings = np.dot(np.dot(U,sigma), VT)

# Prediksi rating
pred_data = pd.DataFrame(all_user_predicted_ratings, columns = pivot_data.columns)
pred_data.head()

"""**Membungkus semua menjadi sebuah fungsi**

**Hal yang harus dilakukan :**

- Buat fungsi untuk merekomendasikan tempat dengan peringkat prediksi tertinggi
- Gunakan fungsi untuk merekomendasikan tempat berdasarkan ID pengguna, peringkat sebelumnya, peringkat yang diprediksi, jumlah tempat
"""

# Merekomendasikan tempat dengan rating prediksi tertinggi
def recommend_places(userID, pivot_data, pred_data, num_recommendations):
  user_index = userID-1 # Index mulai dari 0

  sorted_user_ratings = pivot_data.iloc[user_index].sort_values(ascending = False) # Mengsorting rating pengguna

  sorted_user_predictions = pred_data.iloc[user_index].sort_values(ascending = False) # Prediksi pengguna yang tersortir

  temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)
  temp.index.name = 'ID Tempat yang direkomendasi'
  temp.columns = ['user_ratings', 'user_predictions']

  temp = temp.loc[temp.user_ratings == 0]
  temp = temp.sort_values('user_predictions', ascending = False)
  print('\n  Dibawah ini adalah ID rekomendasi tempat untuk Pelanggan(user_id = {}):\n'.format(userID))
  print(temp.head(num_recommendations))

# Rekomendasi tempat berdasarkan pada userID, past ratings, predicted ratings, num of places

userID = 26


num_recommendations = 10
recommend_places(userID, pivot_data, pred_data, num_recommendations)

"""# EVALUATION

## Metrik evaluasi accuracy
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier


X = data_sort.drop(['score'], axis=1)
y = data_sort['score']
X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, 
                                                     random_state=256)
print(f'Total Sampel pada Keseluruhan: {len(X)}')
print(f'Total Sampel pada Dataset train: {len(X_train)}')
print(f'Total Sampel pada Dataset test: {len(X_test)}')

# Training a binary classifier using Random Forest Algorithm with default hyperparameters
classifier = RandomForestClassifier(random_state=18)
classifier.fit(X_train, y_train)

# Here X_test, y_test are the test data points
predictions = classifier.predict(X_test)

# Importing all necessary libraries
from sklearn.metrics import accuracy_score
# Calculating the accuracy of classifier
print("\nAccuracy of the classifier is: ", accuracy_score(y_test, predictions))

"""## Metrik Evaluasi Precision"""

# Precision
# Importing all necessary libraries
from sklearn.metrics import precision_score

# Calculating the precision score of classifier
print("Precision Score of the classifier is: ", precision_score(y_test, predictions, pos_label='positive', average='micro' ))

precision = precision_score(y_test, predictions, pos_label='positive', average='micro' )
print(precision)

"""## Evaluasi model menggunakan RMSE

RMSE adalah akar kuadrat dari rata-rata kuadrat error. Pengaruh setiap kesalahan pada RMSE sebanding dengan ukuran kesalahan kuadrat; sehingga kesalahan yang lebih besar memiliki efek besar yang tidak proporsional pada RMSE. Akibatnya, RMSE sensitif terhadap outlier.


**Hal yang harus dilakukan:**
* Peringkat aktual yang diberikan oleh pengguna
* Peringkat yang diprediksi untuk suatu tempat
* Hitung RMSE
"""

# Peringkat aktual yang diberikan oleh pengguna
final_ratings_matrix.head()

# Rata-rata peringkat aktual untuk setiap tempat
final_ratings_matrix.mean().head()

# Prediksi peringkat suatu tempat
pred_data.head()

# Rata-rata prediksi rating untuk setiap tempat
pred_data.mean().head()

# Kalkulasi nilai RMSE
rmse_data = pd.concat([final_ratings_matrix.mean(), pred_data.mean()], axis = 1)
rmse_data.columns = ['Avg_actual_rating', 'Avg_predicted_ratings']
print(rmse_data.shape)
rmse_data['place_index'] = np.arange(0, rmse_data.shape[0],1)
rmse_data.head()

plt.plot(rmse_data['Avg_actual_rating'])

plt.title('rmse_data')
plt.ylabel('root_mean_squared_error')

plt.show()

plt.plot(rmse_data['Avg_predicted_ratings'])

plt.title('rmse_data')
plt.ylabel('root_mean_squared_error')

plt.show()

# Nilai RMSE pada SVD Model
RMSE = round((((rmse_data.Avg_actual_rating - rmse_data.Avg_predicted_ratings) ** 2).mean() ** 0.5),5)
print('\n RMSE SVD Model = {}\n'.format(RMSE))

"""** Ringkasan **

Sistem pemberi rekomendasi berbasis popularitas tidak dipersonalisasi dan rekomendasi didasarkan pada jumlah frekuensi, yang mungkin tidak sesuai untuk pengguna. Model berbasis popularitas akan merekomendasikan 5 tempat yang sama untuk semua pengguna tetapi model berbasis Collaborative Filtering telah merekomendasikan seluruh daftar yang berbeda berdasarkan peringkat pengguna.

Collaborative Filtering Berbasis Model adalah sistem rekomendasi yang dipersonalisasi, rekomendasi didasarkan pada perilaku / interaksi pengguna di masa lalu dan tidak bergantung pada informasi tambahan apa pun. Dalam hal ini kami memiliki peringkat yang menunjukkan interaksi.
"""